{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "torchvision.datasets.CIFAR10(root=\"./data\", download=True, train=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Root location: ./data\n",
       "    Split: Train"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "classes = [\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]\n",
    "\n",
    "def plot_sample(X, y, index):\n",
    "    plt.figure(figsize = (15,2))\n",
    "    plt.imshow(X[index])\n",
    "    plt.xlabel(classes[y[index]])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "IMG_SIZE=32\n",
    "NUM_CLASSES = 10\n",
    "TRAINING_BATCH_SIZE = 100\n",
    "TESTING_BATCH_SIZE = 10\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        print(\"Init:\")\n",
    "        self.cn1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
    "        \n",
    "        x = torch.randn(3, IMG_SIZE, IMG_SIZE).view(-1, 3, IMG_SIZE, IMG_SIZE)\n",
    "        print(x.shape)\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "        \n",
    "        print(x.shape)\n",
    "        print(self._to_linear)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self._to_linear, NUM_CLASSES)\n",
    "        \n",
    "    def convs(self, x):\n",
    "        # print(x.shape)\n",
    "        assert x.shape[1] == 3\n",
    "        \n",
    "        x = F.max_pool2d(F.relu(self.cn1(x)), (2, 2))\n",
    "        \n",
    "        self._to_linear = x.flatten(start_dim=1).shape[1]\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # print(\"Forwarding:\")\n",
    "        # print(x.shape)\n",
    "        \n",
    "        x = self.convs(x)        \n",
    "        x = x.view(-1, self._to_linear)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "Net()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Init:\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "7200\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Net(\n",
       "  (cn1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=7200, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 110
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Learning():\n",
    "    def __init__(self, model, optimizer, loss_fn, training_dataloader, testing_dataloader, img_size: int, epochs: int):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.epochs = epochs\n",
    "        self.training_dataloader = training_dataloader\n",
    "        self.testing_dataloader = testing_dataloader\n",
    "        self.testing_batch = list(iter(testing_dataloader))\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        self.device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.log_path = f\"/data/logs/{int(time.time())}.csv\"\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in range(self.epochs):\n",
    "            for i, (batch_X, batch_y) in enumerate(tqdm(iter(self.training_dataloader), desc=\"Epoch \" + str(epoch + 1))):\n",
    "                # print(\"Training:\")\n",
    "                # print(batch_y.shape)\n",
    "                batch_X = (batch_X / 255).to(dtype=torch.float32)\n",
    "                batch_y = F.one_hot(batch_y.long(), num_classes=NUM_CLASSES).to(dtype=torch.float32)\n",
    "                \n",
    "                acc, loss = self._fwd_pass(batch_X, batch_y, train=True)\n",
    "                val_acc, val_loss = self.test()\n",
    "                self.log_to_file(str(epoch) + '-' + str(i), acc, loss, val_acc, val_loss)\n",
    "\n",
    "            print(\"Acc:\", acc)\n",
    "            print(\"Loss:\", loss)\n",
    "\n",
    "\n",
    "    def test(self):\n",
    "        i = random.randint(0, len(self.testing_batch) - 1)\n",
    "        batch_X, batch_y = self.testing_batch[i]\n",
    "        \n",
    "        batch_X = (batch_X / 255.0).to(dtype=torch.float32).view(-1, 3, self.img_size, self.img_size)\n",
    "        batch_y = F.one_hot(batch_y.long(), num_classes=NUM_CLASSES).to(dtype=torch.float32)\n",
    "        \n",
    "        acc, loss = self._fwd_pass(batch_X, batch_y, train=False)\n",
    "\n",
    "        return acc, loss\n",
    "    \n",
    "\n",
    "    def _fwd_pass(self, X, y, train=False):\n",
    "        if train:\n",
    "            self.model.zero_grad()\n",
    "                \n",
    "        output = self.model(X)\n",
    "        # print(y.shape)\n",
    "        # print(output.shape)\n",
    "        # print(y.dtype)\n",
    "        # print(output.dtype)\n",
    "        # print(output[0])\n",
    "        loss = self.loss_fn(y, output)\n",
    "\n",
    "        n_matches = torch.count_nonzero(torch.argmax(output, dim=1) == torch.argmax(y, dim=1)).item()\n",
    "        \n",
    "        if train:\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "        return round(n_matches / len(X), 2), loss\n",
    "    \n",
    "    def log_to_file(self, id: str, train_acc, train_loss, val_acc, val_loss):\n",
    "        append = f\"{id},{train_acc},{train_loss},{val_acc},{val_loss}\\n\"\n",
    "        full_path = os.path.abspath(os.getcwd()) + self.log_path\n",
    "        \n",
    "        with open(full_path, \"a\") as f:\n",
    "            if os.path.getsize(full_path) <= 0:\n",
    "                f.write(\"id,train_acc,train_loss,val_acc,val_loss\\n\")\n",
    "                \n",
    "            f.write(append)\n",
    "            \n",
    "            \n",
    "from torchvision import transforms\n",
    "from torch import optim\n",
    "\n",
    "training_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "testing_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "training_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, transform=training_transforms)\n",
    "training_dataloader = torch.utils.data.DataLoader(training_dataset, shuffle=True, batch_size=TRAINING_BATCH_SIZE)\n",
    "\n",
    "testing_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, transform=testing_transforms)\n",
    "testing_dataloader = torch.utils.data.DataLoader(testing_dataset, shuffle=True, batch_size=TESTING_BATCH_SIZE)\n",
    "\n",
    "# index = 1\n",
    "# plt.figure(figsize = (15,2))\n",
    "# plt.imshow(training_dataset[index][0])\n",
    "# plt.xlabel(classes[training_dataset[index][1]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "source": [
    "\n",
    "net = Net()\n",
    "\n",
    "learning = Learning(\n",
    "    model=net,\n",
    "    optimizer=optim.Adam(net.parameters(), lr=0.001),\n",
    "    loss_fn=nn.MSELoss(),\n",
    "    img_size=IMG_SIZE,\n",
    "    training_dataloader=training_dataloader,\n",
    "    testing_dataloader=testing_dataloader,\n",
    "    epochs=3\n",
    ")\n",
    "\n",
    "learning.train()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Init:\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "7200\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 1: 100%|██████████| 500/500 [00:18<00:00, 27.09it/s]\n",
      "Epoch 2:   1%|          | 3/500 [00:00<00:18, 27.33it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Acc: 0.29\n",
      "Loss: tensor(0.0850, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 2: 100%|██████████| 500/500 [00:18<00:00, 26.96it/s]\n",
      "Epoch 3:   1%|          | 3/500 [00:00<00:18, 27.54it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Acc: 0.25\n",
      "Loss: tensor(0.0840, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 3: 100%|██████████| 500/500 [00:17<00:00, 28.64it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Acc: 0.36\n",
      "Loss: tensor(0.0795, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}